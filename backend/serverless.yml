# Welcome to Serverless!
#
# This file is the main config file for your service.
# It's very minimal at this point and uses default values.
# You can always add more config options for more control.
# We've included some commented out config examples here.
# Just uncomment any of them to get that config option.
#
# For full config options, check the docs:
#    docs.serverless.com
#
# Happy Coding!

service: backend
# app and org for use with dashboard.serverless.com
app: backend
org: miroshnichenko

# You can pin your service to only deploy with a specific Serverless version
# Check out our docs for more details
# frameworkVersion: "=X.X.X"

custom:
  S3_BUCKET: "${self:service}-${opt:stage, self:provider.stage}-pictures"
  TABLE_NAME: "${self:service}-${opt:stage, self:provider.stage}-documents"

provider:
  name: aws
  runtime: nodejs12.x

  stage: dev
  region: eu-central-1

  iamRoleStatements:
    - Effect: Allow
      Action:
        - s3:ListBucket
        - s3:PutObject
        - s3:PutObjectAcl
      Resource: "arn:aws:s3:::${self:custom.S3_BUCKET}/*"
    - Effect: Allow
      Action:
        - dynamodb:Query
        - dynamodb:Scan
        - dynamodb:GetItem
        - dynamodb:PutItem
      Resource: "*"

# you can define service wide environment variables here
  environment:
    S3_BUCKET_NAME: "${self:custom.S3_BUCKET}"
    DYNAMODB_TABLE_NAME: "${self:custom.TABLE_NAME}"

# you can add packaging information here
#package:
#  include:
#    - include-me.js
#    - include-me-dir/**
#  exclude:
#    - exclude-me.js
#    - exclude-me-dir/**

functions:
  getDocuments:
    handler: getDocuments.default
    events:
      - http:
          path: documents
          method: get
          cors: true
  putDocument:
    handler: putDocument.default
    events:
      - http:
          path: documents
          method: post
          cors: true
  uploadImage:
    handler: uploadImage.default
    events:
      - http:
          path: upload
          method: post
          cors: true
#      - websocket: $connect
#      - s3: ${env:BUCKET}
#      - schedule: rate(10 minutes)
#      - sns: greeter-topic
#      - stream: arn:aws:dynamodb:region:XXXXXX:table/foo/stream/1970-01-01T00:00:00.000
#      - alexaSkill: amzn1.ask.skill.xx-xx-xx-xx
#      - alexaSmartHome: amzn1.ask.skill.xx-xx-xx-xx
#      - iot:
#          sql: "SELECT * FROM 'some_topic'"
#      - cloudwatchEvent:
#          event:
#            source:
#              - "aws.ec2"
#            detail-type:
#              - "EC2 Instance State-change Notification"
#            detail:
#              state:
#                - pending
#      - cloudwatchLog: '/aws/lambda/hello'
#      - cognitoUserPool:
#          pool: MyUserPool
#          trigger: PreSignUp
#      - alb:
#          listenerArn: arn:aws:elasticloadbalancing:us-east-1:XXXXXX:listener/app/my-load-balancer/50dc6c495c0c9188/
#          priority: 1
#          conditions:
#            host: example.com
#            path: /hello

#    Define function environment variables here
#    environment:
#      variable2: value2

# you can add CloudFormation resource templates here
resources:
  Resources:
    DDBTable:
      Type: AWS::DynamoDB::Table
      DeletionPolicy: Retain
      Properties:
        AttributeDefinitions:
          - AttributeName: "DocumentId"
            AttributeType: "S"
        KeySchema:
          - AttributeName: "DocumentId"
            KeyType: "HASH"
        ProvisionedThroughput:
          ReadCapacityUnits: 5
          WriteCapacityUnits: 5
        TableName: ${self:provider.environment.DYNAMODB_TABLE_NAME}
    NewResource:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:provider.environment.S3_BUCKET_NAME}
